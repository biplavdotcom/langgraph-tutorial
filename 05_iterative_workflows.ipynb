{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69594c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import os\n",
    "import operator\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b631853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = init_chat_model(model=\"google_genai:gemini-2.0-flash-lite\", api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "evaluator_llm = init_chat_model(model=\"google_genai:gemini-2.5-flash\", api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "optimizer_llm = init_chat_model(model=\"google_genai:gemini-2.5-flash-lite\", api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3d470",
   "metadata": {},
   "source": [
    "# State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "428d9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetState(TypedDict):\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    evaluation: Literal['approved', 'needs_improvement']\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    \n",
    "    tweet_history: Annotated[list[str], operator.add]\n",
    "    feedback_history: Annotated[list[str], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61eb535",
   "metadata": {},
   "source": [
    "# Schema for structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcbc0cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56314/3666854677.py:5: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'descripmax_iterationtion'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  feedback: str = Field(..., descripmax_iterationtion=\"Feedback for the tweet\")\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal['approved', 'needs_improvement'] = Field(..., description=\"Final Evaluation of the tweet\")\n",
    "    feedback: str = Field(..., descripmax_iterationtion=\"Feedback for the tweet\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b491137",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_evaluator_llm = evaluator_llm.with_structured_output(TweetEvaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90c30b",
   "metadata": {},
   "source": [
    "# Nodes (Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state: TweetState):\n",
    "    # prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "                     Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "                     \n",
    "                     Rules:\n",
    "                     - DO NOT use question-answer format.\n",
    "                     - Max 280 characters.\n",
    "                     - Use observational humor, irony, sarcasm, or cultural references.\n",
    "                     - Think in meme logic, punchlines, or relatable takes.\n",
    "                     - Use simple, day to day english.\n",
    "                     - This is version {state['iteration'] + 1}\n",
    "                     \"\"\")\n",
    "    ]\n",
    "    \n",
    "    # send generator_llm\n",
    "    response = generator_llm.invoke(messages).content\n",
    "        \n",
    "    # return response\n",
    "    return{\n",
    "        'tweet': response,\n",
    "        'tweet_history': [response]\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d994067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tweet(state: TweetState):\n",
    "    # prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets based on humor, originality, virality, and tweet format.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "            Evaluate the following tweet:\n",
    "\n",
    "            Tweet: \"{state['tweet']}\"\n",
    "\n",
    "            Use the criteria below to evaluate the tweet:\n",
    "\n",
    "            1. Originality - Is this fresh, or have you seen it a hundred times before?  \n",
    "            2. Humor - Did it genuinely make you smile, laugh, or chuckle?  \n",
    "            3. Punchiness - Is it short, sharp, and scroll-stopping?  \n",
    "            4. Virality Potential - Would people retweet or share it?  \n",
    "            5. Format - Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and under 280 characters)?\n",
    "\n",
    "            Auto-reject if:\n",
    "            - It's written in question-answer format (e.g., \"Why did...\" or \"What happens when...\")\n",
    "            - It exceeds 280 characters\n",
    "            - It reads like a traditional setup-punchline joke\n",
    "            - Dont end with generic, throwaway, or deflating lines that weaken the humor (e.g., “Masterpieces of the auntie-uncle universe” or vague summaries)\n",
    "\n",
    "            ### Respond ONLY in structured format:\n",
    "            - evaluation: \"approved\" or \"needs_improvement\"  \n",
    "            - feedback: One paragraph explaining the strengths and weaknesses \n",
    "    \"\"\")\n",
    "    ]\n",
    "    \n",
    "    response = structured_evaluator_llm.invoke(messages)\n",
    "    return{\n",
    "        'evaluation': response.evaluation,\n",
    "        'feedback': response.feedback,\n",
    "        'feedback_history': [response.feedback]\n",
    "    }  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37f474bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tweet(state: TweetState):\n",
    "    # prompt \n",
    "    messages = [\n",
    "        SystemMessage(content=\"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "            Improve the tweet based on this feedback:\n",
    "            \"{state['feedback']}\"\n",
    "\n",
    "            Topic: \"{state['topic']}\"\n",
    "            Original Tweet:\n",
    "            {state['tweet']}\n",
    "\n",
    "            Re-write it as a short, viral-worthy tweet. Avoid Q&A style and stay under 280 characters.\n",
    "        \"\"\")\n",
    "    ]\n",
    "    \n",
    "    response = optimizer_llm.invoke(messages).content\n",
    "    iteration = state['iteration'] + 1\n",
    "    \n",
    "    return{\n",
    "        'tweet': response,\n",
    "        'iteration': iteration\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090d931",
   "metadata": {},
   "source": [
    "# Conditional edge (function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd1a2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_evaluation(state: TweetState):\n",
    "    if state['evaluation'] == 'approved' or state['iteration'] >= state['max_iterations']:\n",
    "        return 'approved'\n",
    "    else:\n",
    "        return 'needs_improvement'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd0644",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c65eec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(TweetState)\n",
    "\n",
    "# NODE\n",
    "graph.add_node(\"generate\", generate_tweet)\n",
    "graph.add_node(\"evaluate\", evaluate_tweet)\n",
    "graph.add_node(\"optimize\", optimize_tweet)\n",
    "\n",
    "graph.add_edge(START, 'generate')\n",
    "graph.add_edge('generate', 'evaluate')\n",
    "graph.add_conditional_edges('evaluate', route_evaluation, {'approved': END, 'needs_improvement': 'optimize'})\n",
    "graph.add_edge('optimize', 'evaluate')\n",
    "\n",
    "workflow = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d08a6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7fe542281e50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e10af079",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    'topic': 'Graph database usecase',\n",
    "    'iteration': 1,\n",
    "    'max_iterations': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86b0135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\n",
      "Please retry in 1.561591374s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 1\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\n",
      "Please retry in 59.413908912s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 59\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\n",
      "Please retry in 55.264721252s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mgenerate_tweet\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      3\u001b[39m messages = [\n\u001b[32m      4\u001b[39m     SystemMessage(content=\u001b[33m\"\u001b[39m\u001b[33mYou are a funny and clever Twitter/X influencer.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m     HumanMessage(content=\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33m                 \u001b[39m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     16\u001b[39m ]\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# send generator_llm\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m response = \u001b[43mgenerator_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m.content\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# return response\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m{\n\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtweet\u001b[39m\u001b[33m'\u001b[39m: response\n\u001b[32m     24\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:2138\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2135\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:2295\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   2293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   2294\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.max_retries\n\u001b[32m-> \u001b[39m\u001b[32m2295\u001b[39m response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2297\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:269\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    266\u001b[39m params = {\n\u001b[32m    267\u001b[39m     k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service\n\u001b[32m    268\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/tenacity/__init__.py:487\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[32m    486\u001b[39m     retry_state.prepare_for_next_attempt()\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/archeion/langgraph-tutorial/.venv/lib/python3.12/site-packages/tenacity/nap.py:31\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(seconds)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "workflow.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-tutorial (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
